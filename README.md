# NeuroGenMetricsâ€‘3DMRI

> *Preâ€‘trained feature extractors and reference pipelines for computing FID and LPIPS on 3D MRI volumes â€” **code coming soon***.

---

## ğŸŒŸ Motivation

Quantitatively evaluating generative models on volumetric medical images is still tricky.
While 2D naturalâ€‘image models such as **Inceptionâ€‘V3** (FID) and **AlexNet/VGG** (LPIPS) work great for photographs, they ignore domainâ€‘specific texture and physiology in 3D MRI scans.

**NeuroGenMetricsâ€‘3DMRI** will provide:

| Component                                                                | Status        |
| ------------------------------------------------------------------------ | ------------- |
| ğŸ§  3D ResNet trained on large multiâ€‘site T1/T2 datasets                  | `coming soon` |
| ğŸ“ˆ Dropâ€‘in FIDâ€‘3D & LPIPSâ€‘3D scripts (PyTorch)                           | `coming soon` |
| ğŸ”¬ Benchmark configs                                                     | `coming soon` |

---

## ğŸš€ QuickÂ Start

Code will be released as a standard Git repository. Once the first public commit lands you can try it out like this:

```bash
# clone the repo
git clone https://github.com/drinkorange/NeuroGenMetrics-3DMRI.git
cd NeuroGenMetrics-3DMRI

# create and activate an isolated environment
conda create -n neurogenmetrics3d python=3.11 -y
conda activate neurogenmetrics3d

# install Python dependencies
pip install -r requirements.txt

# (optional) fetch pretrained checkpoints
./scripts/download_checkpoints.sh
```

> **Note:** Checkpoints  will be uploaded in the v0.1.0 tag. Stay tuned!

---

## ğŸ”‘ Key Features

* **Domainâ€‘aware backbone** â€” 3D ResNet preâ€‘trained on >5â€¯k multiâ€‘site brain MRIs.
* **Dropâ€‘in API** â€” oneâ€‘liner wrappers to compute *FIDâ€‘3D* and *LPIPSâ€‘3D* for any PyTorch tensor `(B,â€¯C,â€¯D,â€¯H,â€¯W)`.
* **Batch & patch mode** â€” memoryâ€‘efficient evaluation of large volumes with optional slidingâ€‘window.

---

## ğŸ“‚ Dataset Compatibility

This repo is *modalityâ€‘agnostic* as long as inputs are singleâ€‘channel 3D volumes scaled to `[0,â€¯1]`.

| Modality | Tested? | Notes                                                  |
| -------- | ------- | ------------------------------------------------------ |
| T1â€‘w     | âœ…       | default training domain                                |
| T2â€‘w     | âœ…       | minor contrast shift handled by adaptive normalization |
| FLAIR    | ğŸš§      | support planned in v0.2                                |
| DWI/ADC  | ğŸš§      | experimental branch ongoing                            |

---

---

## ğŸ“… Roadmap

* [x] **Internal preâ€‘training completed**
* [ ] **Openâ€‘source cleanup & refactor** â€” tidy code, add tests & docs
* [ ] **v0.1.0 Release** â€” inferenceâ€‘only checkpoints + FID/LPIPS scripts
* [ ] **Multiâ€‘modal support** â€” integrate FLAIR & DWI modalities
* [ ] **Paper / tech report submission**

---

## ğŸ¤ Contributing

Contributions and constructive feedback are welcome after the first public release. Please open an issue to discuss major changes before submitting a PR.

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for the complete license text.

---

<p align="center">
  <em>Code is on the way â€“ watchÂ â˜…Â and stay tuned!</em>
</p>

